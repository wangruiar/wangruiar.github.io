<blockquote>
  <p>转载自超算习堂的在线实训。</p>
</blockquote>

<h2 id="mpi简介">MPI简介</h2>
<p>MPI，全称Message Passing Interface（消息传递接口），是业界定义的一种消息传递标准，用于编写并行计算的程序，广泛应用于高性能计算领域。</p>

<p>标准定义了库函数核心的基本语法和语义，在C, C++和Fortran语言中也可以写出具有消息传递功能的程序。</p>

<p>MPI标准有许多经过良好测试且效率较高的的实现，这些实验是开源的，可供公众使用。</p>

<h2 id="配置mpi环境">配置MPI环境</h2>
<p>为了正常编译MPI代码，需要安装C, C++与Fortran的编译环境。</p>

<p>Ubuntu缺省情况下，并没有提供这些语言的编译环境，因此需要手动安装。如果单独安装这些编译环境非常麻烦。幸运的是，build-essential工具提供了许多与编译相关的软件包，包括gcc/g++/gfortran等编译器、libc6-dev等必要的库与其他工具。于是，我们只需要通过包管理器安装build-essential即可。</p>

<p>MPICH是MPI标准的一种重要的实现，可以免费从网上下载。MPICH的开发与MPI规范的制订是同步进行的，因此MPICH最能反映MPI的变化和发展。MPICH是MPI最流行的非专利实现,由Argonne国家实验室和密西西比州立大学联合开发,具有更好的可移植性,现阶段多流行的是MPICH2。</p>

<p>apt命令的 -y 选项默认安装过程中同意所有的默认选择。</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt install <span class="nt">-y</span> build-essential mpich
</code></pre></div></div>
<h2 id="第一个mpi程序">第一个MPI程序</h2>
<p>首先，我们应该先包含进一个头文件<code class="highlighter-rouge">&lt;mpi.h&gt;</code>，我们使用的函数都在其中。另外，在这之后，MPI程序和普通的C程序的区别在于有一个开始的函数和结束的函数来标识MPI部分，再在这个部分进行你想要进行的操作，现在就来尝试一下！
以下是第一段程序<code class="highlighter-rouge">helloworld.c</code>的内容。</p>
<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cm">/*
int MPI_Init(int *argc, char **argv);//通过MPI_Init函数进入MPI环境并完成所有的初始化工作，标志并行代码的开始。
int MPI_Finalize(void);//通过MPI_Finalize函数从MPI环境中退出，标志并行代码的结束，如果不是MPI程序最后一条可执行语句，则运行结果不可知。
*/</span>
<span class="cp">#include &lt;mpi.h&gt;
#include &lt;stdio.h&gt;
</span><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">**</span><span class="n">argv</span><span class="p">)</span>
<span class="p">{</span>
	<span class="c1">//your code here
</span>	<span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">argv</span><span class="p">);</span>
	<span class="n">puts</span><span class="p">(</span><span class="s">"Hello World!"</span><span class="p">);</span>
	<span class="n">MPI_Finalize</span><span class="p">();</span>
	<span class="c1">//end of your code
</span>
	<span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>
<p>按下面的指令编译运行（以下都以四个进程执行为例）。</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mpicc helloworld.c <span class="nt">-o</span> helloworld
mpirun <span class="nt">-np</span> 4 ./mpihelloworld
</code></pre></div></div>
<p>得到输出。</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Hello World!
Hello World!
Hello World!
Hello World!
</code></pre></div></div>
<h2 id="获取进程数量">获取进程数量</h2>
<p>在MPI编程中，我们常常需要获取指定通信域的进程个数，以确定程序的规模。</p>

<p>一组可以相互发送消息的进程集合叫做通信子，通常由MPI_Init()在用户启动程序时，定义由用户启动的所有进程所组成的通信子，缺省值为 MPI_COMM_WORLD 。这个参数是MPI通信操作函数中必不可少的参数，用于限定参加通信的进程的范围。</p>

<p>使用函数MPI_Comm_size获取通信域中的进程个数并打印出来。</p>
<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cm">/*
int MPI_Comm_size(MPI_Comm comm, int *rank);//获取指定通信域的进程个数。其中，第一个参数是通信子，第二个参数返回进程的个数
*/</span>
<span class="cp">#include &lt;stdio.h&gt;
#include &lt;mpi.h&gt;
</span>
<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">**</span><span class="n">argv</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">int</span> <span class="n">numprocs</span><span class="p">;</span>
	<span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">argv</span><span class="p">);</span>

	<span class="c1">//your code here
</span>	<span class="n">MPI_Comm_size</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">numprocs</span><span class="p">);</span>
	<span class="c1">//end of your code
</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"Hello World! The number of processes is %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span><span class="n">numprocs</span><span class="p">);</span>

	<span class="n">MPI_Finalize</span><span class="p">();</span>
	<span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
<span class="cm">/*
Hello World! The number of processes is 4
Hello World! The number of processes is 4
Hello World! The number of processes is 4
Hello World! The number of processes is 4
*/</span>
</code></pre></div></div>
<h2 id="获取进程id">获取进程id</h2>
<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cm">/*
int MPI_Comm_rank(MPI_Comm comm, int *rank);//获得当前进程在指定通信域中的编号，将自身与其他程序区分。其中，第一个参数是通信子，第二个参数返回进程的编号。
*/</span>
<span class="cp">#include &lt;stdio.h&gt;
#include &lt;mpi.h&gt;
</span>
<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">**</span><span class="n">argv</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">int</span> <span class="n">myid</span><span class="p">,</span> <span class="n">numprocs</span><span class="p">;</span>
	<span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">argv</span><span class="p">);</span>

  <span class="n">MPI_Comm_size</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">numprocs</span><span class="p">);</span>

	<span class="c1">//your code here
</span>	<span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">myid</span><span class="p">);</span>
	<span class="c1">//end of your code
</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"Hello World!I'm rank %d of %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">myid</span><span class="p">,</span> <span class="n">numprocs</span><span class="p">);</span>

	<span class="n">MPI_Finalize</span><span class="p">();</span>
	<span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
<span class="cm">/*
Hello World!I'm rank 3 of 4
Hello World!I'm rank 0 of 4
Hello World!I'm rank 1 of 4
Hello World!I'm rank 2 of 4
*/</span>
</code></pre></div></div>
<h2 id="获取处理器名">获取处理器名</h2>
<p>有时候在实际处理中我们可能需要将进程迁移至不同的处理器，而MPI提供了获取处理器名的函数以简单地允许这种行为。</p>

<p>注意在MPI中不需要定义这种迁移。</p>
<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cm">/*
int MPI_Get_processor_name ( char *name, int *resultlen);//实际节点的唯一说明字;在name中返回结果的长度;
*/</span>
<span class="cp">#include &lt;stdio.h&gt;
#include &lt;mpi.h&gt;
</span>
<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">**</span><span class="n">argv</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">int</span> <span class="n">len</span><span class="p">;</span>
	<span class="kt">char</span> <span class="n">name</span><span class="p">[</span><span class="n">MPI_MAX_PROCESSOR_NAME</span><span class="p">];</span>
	<span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">argv</span><span class="p">);</span>

	<span class="c1">//your code here
</span>	<span class="n">MPI_Get_processor_name</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">len</span><span class="p">);</span>
	<span class="c1">//end of your code
</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"Hello, world. I am %s.</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">name</span><span class="p">);</span>

	<span class="n">MPI_Finalize</span><span class="p">();</span>
	<span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
<span class="cm">/*
Hello, world. I am 60e876622717.
Hello, world. I am 60e876622717.
Hello, world. I am 60e876622717.
Hello, world. I am 60e876622717.
*/</span>
</code></pre></div></div>
<h2 id="运行时间">运行时间</h2>
<p>在实际编程中，计时是一个很实用的功能。
在MPI编程我们可以使用MPI_Wtime函数在并行代码中计算运行时间，用MPI_Wtick来查看精度。</p>
<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cm">/*
double MPI_Wtime();//返回一个用浮点数表示的秒数, 它表示从过去某一时刻到调用时刻所经历的时间
double MPI_Wtick();//返回MPI_WTIME的精度，单位是秒，可以认为是一个时钟滴答所占用的时间
*/</span>
<span class="cp">#include&lt;stdio.h&gt;
#include&lt;mpi.h&gt;
</span>
<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">**</span><span class="n">argv</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">int</span> <span class="n">myid</span><span class="p">,</span> <span class="n">numprocs</span><span class="p">;</span>
	<span class="kt">double</span> <span class="n">start</span><span class="p">,</span> <span class="n">finish</span><span class="p">;</span>

	<span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">argv</span><span class="p">);</span>

	<span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">myid</span><span class="p">);</span>
	<span class="n">MPI_Comm_size</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">numprocs</span><span class="p">);</span>

	<span class="c1">//your code here
</span>	<span class="n">start</span><span class="o">=</span><span class="n">MPI_Wtime</span><span class="p">();</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"The precision is: %.9lf</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span><span class="n">MPI_Wtick</span><span class="p">());</span>
	<span class="n">finish</span><span class="o">=</span><span class="n">MPI_Wtime</span><span class="p">();</span>
	<span class="c1">//your code here
</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"Hello World!I'm rank %d of %d, running %f seconds.</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">myid</span><span class="p">,</span> <span class="n">numprocs</span><span class="p">,</span> <span class="n">finish</span><span class="o">-</span><span class="n">start</span><span class="p">);</span>

	<span class="n">MPI_Finalize</span><span class="p">();</span>
	<span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
<span class="cm">/*
The precision is: 0.000000001
Hello World!I'm rank 3 of 4, running 0.000031 seconds.
The precision is: 0.000000001
Hello World!I'm rank 0 of 4, running 0.000019 seconds.
The precision is: 0.000000001
Hello World!I'm rank 1 of 4, running 0.000026 seconds.
The precision is: 0.000000001
Hello World!I'm rank 2 of 4, running 0.000022 seconds.
*/</span>
</code></pre></div></div>
<h2 id="同步">同步</h2>
<p>在实际工作中，我们常常会因为许多原因需要进行同步操作。
例如，希望保证所有进程中并行代码在某个地方同时开始运行，或者在某个函数调用结束之前不能返回。
这时候我们就需要使用到MPI_Barrier函数。</p>

<p>在此示例程序中，可能是否调用函数不影响最终输出，但这并不意味着效果相同。</p>
<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cm">/*
int MPI_Barrier(MPI_Comm comm);//阻止调用直到communicator中所有进程已经完成调用，就是说，任意一次进程的调用只能在所有communicator中的成员已经开始调用之后进行。
*/</span>
<span class="cp">#include&lt;stdio.h&gt;
#include&lt;mpi.h&gt;
</span>
<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">**</span><span class="n">argv</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">int</span> <span class="n">myid</span><span class="p">,</span> <span class="n">numprocs</span><span class="p">;</span>
	<span class="kt">double</span> <span class="n">start</span><span class="p">,</span> <span class="n">finish</span><span class="p">;</span>

	<span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">argv</span><span class="p">);</span>

    <span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">myid</span><span class="p">);</span>
    <span class="n">MPI_Comm_size</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">numprocs</span><span class="p">);</span>

	<span class="c1">//your code here
</span>	<span class="n">MPI_Barrier</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">);</span>
	<span class="c1">//end of your code
</span>
	<span class="n">start</span> <span class="o">=</span> <span class="n">MPI_Wtime</span><span class="p">();</span>

	<span class="n">printf</span><span class="p">(</span><span class="s">"The precision is: %f</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">MPI_Wtick</span><span class="p">());</span>

	<span class="n">finish</span> <span class="o">=</span> <span class="n">MPI_Wtime</span><span class="p">();</span>

	<span class="n">printf</span><span class="p">(</span><span class="s">"Hello World!I'm rank %d of %d, running %f seconds.</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">myid</span><span class="p">,</span> <span class="n">numprocs</span><span class="p">,</span> <span class="n">finish</span><span class="o">-</span><span class="n">start</span><span class="p">);</span>

	<span class="n">MPI_Finalize</span><span class="p">();</span>
	<span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
<span class="cm">/*
The precision is: 0.000000
Hello World!I'm rank 0 of 4, running 0.000023 seconds.
The precision is: 0.000000
Hello World!I'm rank 1 of 4, running 0.000016 seconds.
The precision is: 0.000000
Hello World!I'm rank 2 of 4, running 0.000017 seconds.
The precision is: 0.000000
Hello World!I'm rank 3 of 4, running 0.000015 seconds.
*/</span>
</code></pre></div></div>
<h2 id="消息传递">消息传递</h2>
<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cm">/*
int MPI_Send(
	void *msg_buf_p,//发送缓冲区的起始地址；
	int msg_size,//缓冲区大小
	MPI_Datatype msg_type,//发送信息的数据类型
	int dest,//目标进程的id值
	int tag,//消息标签
	MPI_Comm communicator);//通信子
int MPI_Recv(
	void *msg_buf_p,//缓冲区的起始地址；
	int buf_size,//缓冲区大小；
	MPI_Datatype msg_type,//发送信息的数据类型；
	int source,//目标进程的id值；
	int tag,//消息标签；
	MPI_Comm communicator,//通信子；
	MPI_Status *status_p);//status_p对象，包含实际接收到的消息的有关信息
*/</span>
<span class="cp">#include &lt;stdio.h&gt;
#include &lt;string.h&gt;
#include &lt;mpi.h&gt;
</span>
<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">**</span><span class="n">argv</span><span class="p">)</span>
<span class="p">{</span>
	<span class="kt">int</span> <span class="n">myid</span><span class="p">,</span> <span class="n">numprocs</span><span class="p">,</span> <span class="n">source</span><span class="p">;</span>
	<span class="n">MPI_Status</span> <span class="n">status</span><span class="p">;</span>
	<span class="kt">char</span> <span class="n">message</span><span class="p">[</span><span class="mi">100</span><span class="p">];</span>

	<span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">argv</span><span class="p">);</span>
	<span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">myid</span><span class="p">);</span>
    <span class="n">MPI_Comm_size</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">numprocs</span><span class="p">);</span>

    <span class="k">if</span><span class="p">(</span><span class="n">myid</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    	<span class="n">strcpy</span><span class="p">(</span><span class="n">message</span><span class="p">,</span> <span class="s">"hello world!"</span><span class="p">);</span>

    	<span class="c1">//your code here
</span>    	<span class="n">MPI_Send</span><span class="p">(</span><span class="n">message</span><span class="p">,</span> <span class="n">strlen</span><span class="p">(</span><span class="n">message</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">MPI_CHAR</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">myid</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">);</span>
    	<span class="c1">//end of your code
</span>	<span class="p">}</span>
	<span class="k">else</span> <span class="p">{</span> <span class="c1">//myid == 0
</span>		<span class="k">for</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="mi">1</span><span class="p">;</span> <span class="n">source</span><span class="o">&lt;</span><span class="n">numprocs</span><span class="p">;</span> <span class="n">source</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
			<span class="c1">//your code here
</span>			<span class="n">MPI_Recv</span><span class="p">(</span><span class="n">message</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">MPI_CHAR</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="n">MPI_COMM_WORLD</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">status</span><span class="p">);</span>
			<span class="c1">//end of your code
</span>
			<span class="n">printf</span><span class="p">(</span><span class="s">"%s</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">message</span><span class="p">);</span>
		<span class="p">}</span>
	<span class="p">}</span>

	<span class="n">MPI_Finalize</span><span class="p">();</span>
	<span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
<span class="cm">/*
hello world!
hello world!
hello world!
*/</span>
</code></pre></div></div>
<h2 id="地址偏移量">地址偏移量</h2>
<p>待续</p>
